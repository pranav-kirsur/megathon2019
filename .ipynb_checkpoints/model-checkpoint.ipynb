{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFeatures = 12\n",
    "nDataPoints = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.47404728e-01, 3.05334291e-01, 4.78484360e-01, 6.50575406e-02,\n",
       "        8.62759702e-01, 3.91733319e-01, 5.96249466e-01, 9.45385402e-02,\n",
       "        8.06042025e-01, 5.55785905e-01, 3.94719598e-01, 1.89804261e-01],\n",
       "       [2.21603713e-01, 7.50109665e-01, 4.45752308e-02, 5.16864344e-01,\n",
       "        5.10168571e-02, 4.77690808e-01, 8.73611603e-01, 7.39782046e-01,\n",
       "        3.08567407e-01, 4.23005826e-01, 1.25086938e-02, 5.68703342e-02],\n",
       "       [7.87395126e-01, 5.01186594e-02, 6.52600271e-01, 9.92972972e-01,\n",
       "        8.91252734e-01, 6.59529192e-01, 3.73885957e-01, 8.12109404e-01,\n",
       "        7.74295789e-01, 6.80316223e-01, 9.03617262e-01, 3.26412345e-01],\n",
       "       [5.85476853e-01, 4.66860162e-02, 5.50124458e-01, 4.47793476e-01,\n",
       "        8.48636247e-02, 3.37893577e-01, 6.06425886e-01, 2.97248478e-01,\n",
       "        2.51842602e-01, 6.29318699e-01, 2.86304061e-01, 4.60272862e-01],\n",
       "       [5.29664672e-01, 4.74028088e-01, 3.97446728e-01, 8.11997093e-01,\n",
       "        4.94819429e-01, 4.05256462e-01, 4.70446540e-01, 7.00281271e-01,\n",
       "        8.22097612e-01, 7.35842568e-01, 4.15317470e-02, 8.79434769e-02],\n",
       "       [8.87162693e-01, 9.50393914e-01, 8.49304840e-01, 8.21367555e-01,\n",
       "        1.18421057e-01, 4.34446138e-01, 7.57853692e-01, 6.22364223e-01,\n",
       "        5.51065597e-01, 9.74398494e-01, 6.51983773e-01, 7.98822467e-01],\n",
       "       [4.39616800e-01, 2.75875501e-03, 1.56415074e-01, 4.46048511e-01,\n",
       "        4.97500304e-01, 3.79503180e-01, 7.97622001e-01, 5.04305354e-01,\n",
       "        9.24816615e-01, 5.01673860e-01, 2.96290489e-02, 3.37898390e-01],\n",
       "       [5.90080719e-01, 2.85141248e-01, 8.97767931e-01, 7.59704396e-01,\n",
       "        8.54244911e-01, 9.85213839e-01, 7.48627880e-01, 1.92341026e-02,\n",
       "        4.49752600e-01, 1.93713471e-01, 9.98329521e-01, 3.98469555e-01],\n",
       "       [6.32196230e-01, 5.10660765e-01, 4.75249730e-01, 6.13212229e-01,\n",
       "        7.69109059e-01, 2.47395893e-01, 2.42179466e-01, 9.95271573e-01,\n",
       "        7.23503284e-01, 7.28768963e-01, 6.80815720e-01, 7.29122079e-01],\n",
       "       [2.93083671e-02, 6.82445377e-01, 8.51914476e-01, 8.82309366e-01,\n",
       "        9.54105693e-01, 7.86713813e-01, 1.78643199e-01, 8.58340348e-01,\n",
       "        8.98094544e-01, 7.18948251e-01, 4.08340739e-01, 7.92779694e-01],\n",
       "       [7.88235523e-01, 4.26852937e-01, 8.28697176e-01, 9.10433671e-01,\n",
       "        1.68199224e-01, 5.32626094e-01, 7.69687738e-01, 3.46035438e-01,\n",
       "        5.34136650e-01, 7.54536844e-01, 3.92438523e-01, 3.75654550e-01],\n",
       "       [6.55445191e-01, 4.10693314e-01, 8.65638946e-01, 4.40956084e-01,\n",
       "        1.60638401e-01, 4.98848483e-01, 4.39112439e-01, 9.81563940e-01,\n",
       "        7.52297308e-01, 4.88437051e-01, 1.85358662e-01, 8.57349985e-01],\n",
       "       [8.17674836e-01, 1.96483974e-01, 7.26313089e-01, 4.33444350e-01,\n",
       "        2.88859272e-01, 9.94698353e-02, 4.45435653e-01, 2.25066084e-02,\n",
       "        6.63786116e-01, 4.33545908e-01, 1.16237661e-01, 4.23953934e-01],\n",
       "       [7.65644578e-01, 9.25837021e-01, 3.08713872e-01, 8.01783111e-01,\n",
       "        8.39291585e-01, 2.65914672e-01, 8.85483579e-01, 5.45076802e-01,\n",
       "        3.28241568e-01, 3.53215998e-01, 7.28570574e-01, 7.47995617e-01],\n",
       "       [2.80794285e-01, 5.40886570e-01, 3.79193704e-01, 7.97100666e-01,\n",
       "        9.52613978e-01, 6.33341228e-01, 6.58746649e-02, 3.57053500e-01,\n",
       "        7.50229581e-02, 6.15039149e-01, 4.64206274e-01, 2.09963278e-01],\n",
       "       [7.83401436e-02, 7.76560632e-01, 2.34142729e-01, 6.76457235e-01,\n",
       "        6.10653980e-01, 2.18680218e-01, 5.15532741e-01, 8.86630629e-01,\n",
       "        9.03601432e-01, 2.80011032e-01, 3.61770399e-01, 4.86677921e-02],\n",
       "       [4.85634311e-01, 2.95968093e-01, 2.45713894e-01, 7.46825683e-01,\n",
       "        6.79904357e-01, 6.42805864e-01, 2.36540380e-01, 3.28685665e-01,\n",
       "        7.41629798e-01, 2.40605944e-01, 1.36310158e-01, 4.33435718e-01],\n",
       "       [8.53170699e-01, 8.82617058e-01, 4.79597016e-01, 9.19494367e-01,\n",
       "        6.82966165e-01, 7.42284183e-01, 2.94143157e-01, 4.87719822e-01,\n",
       "        7.24756804e-01, 1.77317768e-01, 6.41664248e-01, 8.10653988e-01],\n",
       "       [6.39104471e-01, 6.16963768e-02, 5.60073769e-01, 5.04412321e-01,\n",
       "        5.41144942e-01, 7.17762902e-01, 2.80113086e-01, 1.67220514e-01,\n",
       "        6.57705129e-01, 7.19183930e-01, 8.07520789e-02, 5.83684437e-01],\n",
       "       [1.59498977e-01, 1.37188206e-01, 1.67505221e-01, 7.93534463e-01,\n",
       "        8.75249761e-01, 9.36695808e-01, 5.36339942e-01, 8.80649264e-01,\n",
       "        5.40715333e-01, 3.85445973e-04, 8.71101314e-01, 7.98965735e-02],\n",
       "       [5.33045313e-01, 3.84377977e-02, 7.04512537e-01, 3.61899594e-01,\n",
       "        1.24517944e-01, 8.53224762e-01, 4.98205983e-01, 4.92168207e-01,\n",
       "        2.85516302e-01, 4.32964027e-01, 1.67013056e-01, 9.68282395e-01],\n",
       "       [6.69863432e-01, 8.43535817e-01, 1.86500711e-01, 8.93254327e-01,\n",
       "        2.74251499e-01, 1.37784803e-01, 8.90219100e-01, 5.70316176e-02,\n",
       "        3.52858730e-01, 7.80841769e-01, 4.83636963e-01, 2.88621234e-01],\n",
       "       [4.72164493e-01, 2.62886400e-01, 9.14576160e-01, 3.13373044e-01,\n",
       "        6.79205015e-01, 3.22108797e-01, 4.98723337e-01, 3.41210263e-01,\n",
       "        9.22876959e-01, 5.95829163e-01, 9.83267671e-01, 4.47626023e-01],\n",
       "       [6.15735844e-01, 1.45693159e-02, 4.90067953e-01, 1.41928415e-01,\n",
       "        3.58443256e-01, 7.11599232e-01, 7.96741271e-01, 7.53451364e-01,\n",
       "        8.78592581e-02, 5.34355703e-01, 7.93339056e-01, 5.15933182e-01],\n",
       "       [1.62939837e-01, 9.76625724e-01, 4.66257689e-01, 8.18723831e-01,\n",
       "        7.30066132e-01, 5.59018022e-01, 8.62239035e-02, 9.81130732e-01,\n",
       "        2.85419199e-01, 3.77266992e-01, 6.55000595e-01, 2.07414164e-01],\n",
       "       [3.22729331e-01, 7.71350166e-01, 1.04280198e-02, 6.02949059e-01,\n",
       "        9.83411531e-01, 9.44078990e-01, 3.71948501e-02, 6.08932322e-01,\n",
       "        9.32560674e-01, 9.35096570e-01, 4.60347160e-01, 7.39154006e-01],\n",
       "       [7.66827681e-01, 8.18272304e-01, 8.30225975e-01, 1.64281365e-01,\n",
       "        3.74505582e-01, 8.62720145e-01, 6.42060325e-01, 1.99956598e-01,\n",
       "        1.93360246e-01, 6.62932652e-01, 6.71538101e-01, 9.41271088e-01],\n",
       "       [5.32398528e-01, 6.21186694e-01, 3.45132045e-01, 4.08916437e-01,\n",
       "        2.53581795e-01, 7.64935383e-02, 9.76603115e-01, 6.40253760e-01,\n",
       "        8.52247568e-01, 2.33184580e-01, 1.87459535e-01, 7.58058262e-02],\n",
       "       [1.86145254e-01, 4.67706576e-01, 5.34087156e-01, 1.26048252e-01,\n",
       "        6.45042412e-01, 5.65998416e-01, 7.17193908e-01, 9.93895250e-01,\n",
       "        3.22681016e-01, 4.84097100e-01, 8.65500087e-01, 7.96812437e-01],\n",
       "       [3.91488710e-01, 6.24410147e-01, 7.99882015e-01, 4.71170114e-01,\n",
       "        7.56844543e-01, 6.33110426e-01, 2.02965996e-01, 2.14709904e-02,\n",
       "        7.29801067e-01, 3.32745909e-01, 2.20887731e-01, 8.76527086e-01],\n",
       "       [9.45678247e-01, 6.58748121e-01, 4.78290677e-01, 1.21213132e-01,\n",
       "        6.17060438e-01, 2.51377055e-01, 4.04141316e-01, 1.10571086e-01,\n",
       "        6.62359047e-01, 6.26057424e-01, 3.30221825e-01, 4.93180768e-02],\n",
       "       [4.46625069e-01, 2.29697366e-01, 7.50667720e-01, 6.56903896e-01,\n",
       "        1.39112066e-01, 1.28079440e-01, 8.01108745e-01, 8.91376070e-01,\n",
       "        1.77356959e-01, 1.71245918e-01, 8.11522585e-02, 1.91681805e-01],\n",
       "       [9.52124094e-01, 6.84063021e-01, 2.91034150e-01, 8.07782904e-01,\n",
       "        7.82457238e-01, 9.08346015e-01, 8.16543844e-03, 6.03337333e-01,\n",
       "        2.70745088e-01, 1.21273574e-01, 9.91281067e-01, 5.34244682e-01],\n",
       "       [6.15159442e-01, 8.40261807e-01, 8.00088743e-02, 6.61554899e-01,\n",
       "        9.98581228e-01, 6.90846317e-01, 4.06998595e-01, 6.50432262e-01,\n",
       "        2.32394060e-01, 7.49843962e-01, 4.43932451e-01, 9.54992419e-01],\n",
       "       [6.71275800e-01, 9.21791498e-01, 9.84135455e-01, 3.71555535e-01,\n",
       "        6.50528246e-01, 2.48848534e-01, 8.15457475e-01, 5.59950242e-01,\n",
       "        5.90958546e-01, 7.47657394e-02, 1.84909273e-01, 7.52893036e-02],\n",
       "       [3.86147009e-01, 5.89404694e-01, 6.98862340e-01, 8.87150412e-01,\n",
       "        7.29731514e-01, 6.57007631e-01, 6.90466547e-01, 7.66330979e-01,\n",
       "        8.12598200e-01, 1.73392517e-01, 3.83020568e-01, 4.74038294e-01],\n",
       "       [4.48694901e-01, 2.96403348e-02, 3.43561063e-01, 2.11383383e-01,\n",
       "        7.43382068e-01, 9.16505223e-01, 4.26175113e-01, 4.05276417e-01,\n",
       "        8.16032963e-01, 6.50207302e-01, 8.69187499e-01, 5.45039974e-01],\n",
       "       [9.02444835e-02, 7.78369237e-01, 9.31527714e-01, 1.74282665e-01,\n",
       "        2.34374978e-01, 7.81800132e-01, 2.93920199e-01, 3.59714383e-01,\n",
       "        8.70393482e-02, 5.80630121e-01, 5.93617089e-01, 5.24044190e-01],\n",
       "       [8.75851518e-02, 8.43576123e-01, 1.74600505e-02, 6.76119330e-01,\n",
       "        2.49256470e-01, 7.22806508e-01, 9.66102224e-01, 8.41069128e-01,\n",
       "        6.81971260e-01, 5.49267357e-01, 8.89012354e-02, 4.66008541e-01],\n",
       "       [3.29268912e-01, 4.24968015e-01, 9.78808300e-01, 7.36890346e-01,\n",
       "        4.21046490e-01, 4.95712590e-02, 7.36915383e-02, 6.98382263e-01,\n",
       "        9.31236415e-01, 1.63668868e-01, 6.92189936e-01, 3.95334288e-01],\n",
       "       [1.02388258e-01, 1.46609225e-01, 3.84803800e-01, 7.90661019e-01,\n",
       "        3.27114870e-01, 3.24369422e-02, 2.54885796e-01, 2.48636069e-01,\n",
       "        9.74737822e-01, 8.08098531e-01, 4.31131671e-01, 2.82561961e-01],\n",
       "       [9.92746614e-02, 3.50774687e-01, 9.17582151e-01, 2.95961651e-01,\n",
       "        8.48032936e-01, 7.47730313e-01, 2.10490306e-01, 1.85415101e-01,\n",
       "        8.99976501e-01, 5.03958128e-02, 4.27984946e-01, 2.27958120e-01],\n",
       "       [9.31434738e-02, 1.28091694e-01, 6.12522315e-02, 8.17602732e-01,\n",
       "        8.59585053e-01, 3.63310053e-02, 8.87136919e-01, 9.17053800e-01,\n",
       "        9.00384830e-01, 1.25658258e-01, 8.33608951e-01, 7.37389982e-01],\n",
       "       [6.58635216e-01, 3.41957955e-02, 7.31858631e-02, 8.76777495e-01,\n",
       "        2.34629937e-01, 1.86806570e-01, 3.67890787e-01, 7.09657206e-01,\n",
       "        9.22252984e-02, 5.38844813e-01, 4.18140000e-01, 3.85615276e-01],\n",
       "       [7.56539571e-02, 6.14135572e-01, 3.76441602e-01, 3.37363718e-01,\n",
       "        4.32293787e-01, 5.63358839e-01, 1.48294800e-01, 8.18036405e-02,\n",
       "        4.32493723e-01, 3.22309555e-01, 5.92467652e-01, 7.71612811e-01],\n",
       "       [3.52526272e-01, 1.28358180e-01, 5.61030244e-01, 7.60299673e-01,\n",
       "        7.77212664e-01, 6.58859798e-01, 4.77396191e-01, 6.00955182e-01,\n",
       "        3.55415161e-01, 3.08003283e-01, 8.29213996e-01, 6.30768137e-02],\n",
       "       [5.20078304e-01, 6.50798761e-01, 2.10056275e-01, 2.94290851e-01,\n",
       "        8.12969600e-01, 2.36491105e-01, 2.17489634e-01, 3.09224762e-01,\n",
       "        3.43671842e-01, 1.61928429e-01, 5.09206421e-01, 9.48991240e-01],\n",
       "       [1.65519596e-02, 5.66999001e-01, 5.30278163e-01, 6.32048823e-01,\n",
       "        9.04005001e-01, 2.39695755e-01, 1.56247914e-01, 7.02815991e-01,\n",
       "        3.86513451e-01, 6.62380320e-01, 8.42050778e-01, 1.57801487e-02],\n",
       "       [1.09976795e-01, 7.92502514e-01, 4.80359121e-01, 6.29474098e-01,\n",
       "        6.82881119e-01, 6.56159821e-01, 7.45153278e-01, 7.28590783e-01,\n",
       "        7.36742324e-01, 2.95094460e-02, 4.47911787e-01, 5.27157571e-01],\n",
       "       [5.51849287e-01, 6.95224537e-01, 8.97769063e-03, 3.19967563e-01,\n",
       "        9.76551736e-01, 4.24245650e-01, 8.32239733e-01, 5.05444615e-01,\n",
       "        2.16822026e-01, 8.76869166e-01, 8.56572653e-01, 5.30977754e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = loadtxt(\"features-test.csv\", delimiter=',') #Sentences x Features\n",
    "\n",
    "X = dataset[:,0:nFeatures]\n",
    "y = dataset[:,nFeatures:]\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=nFeatures, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 32us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 34us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 30us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 35us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 34us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 34us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 33us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 35us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 34us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 30us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 26us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 39us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 30us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 36us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 32us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 35us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 25us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 25us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 26us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 26us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 26us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 34us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 25us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 26us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 26us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 33us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 26us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 32us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 36us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 32us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 41us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 33us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 30us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 27us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 33us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 30us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 32us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 30us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 30us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 33us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 30us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 43us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 34us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 34us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 35us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 33us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 44us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 29us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 37us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 42us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 31us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 28us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 32us/step - loss: 7.7666 - mean_absolute_error: 0.4819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12d810ed0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 584us/step\n",
      "Mean Absolute Error Percentage: 0.9637126922607422\n"
     ]
    }
   ],
   "source": [
    "_, mean_absolute_error = model.evaluate(X, y)\n",
    "print('Mean Absolute Error Percentage: '+str(mean_absolute_error*100/nDataPoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
